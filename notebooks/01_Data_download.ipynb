{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I played the role of a consultant working for one of the air carriers. The task was to optimize the process of providing and analyzing data.\n",
    "\n",
    "# Business context\n",
    "\n",
    "Recently, the air carrier received access to API service for downloading data. (https://api-datalab.coderslab.com/api/v2)[documentation](https://api-datalab.coderslab.com/v2/docs/) <br>\n",
    "Previously data was available only manually from external application. Moreover, the application had additional row limitation. Due to the limits imposed in the application, data processing and analysis were extremely ineffective - requiring involvement of many employees, which was additionally associated with delays in providing data, resulting in delays in making important decisions.<br>\n",
    "\n",
    "The client does not have its own unit responsible for data analysis. That is why our employer was hired to create a reporting and analytical system that will speed up the time of receiving data and eliminate the manual effort required to process the data. As a result, the customer expects to be able to receive reports on aircraft delays faster and to learn delays causes, which will enable him to determine preventive actions.\n",
    "\n",
    "# Data Engineer module\n",
    "\n",
    "According to the documentation, I find that 4 API endpoints have been made available:\n",
    " - `airport` - airport data,\n",
    " - `weather` - information about the recorded weather at the airport on a given day,\n",
    " - `aircraft` - aircraft data\n",
    " - `flights` - data on departures from a given airport per day\n",
    "\n",
    "I am also provided with airportIDs which the air carrier is serving - `airports.csv`.\n",
    "\n",
    "My task is to download the provided data into the workspace, which will be later uploaded to the database.\n",
    "\n",
    "Data precessing and analysis will be carried out in subsequent notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining connection parameters to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORIGIN_AIRPORT_ID': 11638,\n",
       " 'DISPLAY_AIRPORT_NAME': 'Fresno Air Terminal',\n",
       " 'ORIGIN_CITY_NAME': 'Fresno, CA',\n",
       " 'NAME': 'FRESNO YOSEMITE INTERNATIONAL, CA US'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airportId = 11638\n",
    "TOKEN=\"iKRsQ8vdqgT903o2vH1rsejOeQ0F7YC9TvutH6Wk\"\n",
    "headers= {'Authorization': TOKEN}\n",
    "response = requests.get(f'https://api-datalab.coderslab.com/api/v2/airport/{airportId}', headers = headers)\n",
    "Airport_data = response.json()\n",
    "Airport_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the `airports.csv` file and adapting to further steps to download from subsequent endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10874',\n",
       " '11233',\n",
       " '13360',\n",
       " '15008',\n",
       " '11638',\n",
       " '14150',\n",
       " '15323',\n",
       " '14814',\n",
       " '12007',\n",
       " '11337',\n",
       " '13342',\n",
       " '15070',\n",
       " '13244',\n",
       " '12280',\n",
       " '15096',\n",
       " '11641',\n",
       " '13832',\n",
       " '10268',\n",
       " '10397',\n",
       " '15041',\n",
       " '10529',\n",
       " '12119',\n",
       " '11537',\n",
       " '11092',\n",
       " '10581',\n",
       " '13829',\n",
       " '15389',\n",
       " '10140',\n",
       " '12389',\n",
       " '11648',\n",
       " '15023',\n",
       " '11982',\n",
       " '10967',\n",
       " '11525',\n",
       " '10792',\n",
       " '14259',\n",
       " '11637',\n",
       " '10466',\n",
       " '10599',\n",
       " '10208',\n",
       " '15841',\n",
       " '14831',\n",
       " '12898',\n",
       " '13241',\n",
       " '13367',\n",
       " '11481',\n",
       " '14108',\n",
       " '13931',\n",
       " '13873',\n",
       " '10157',\n",
       " '10245',\n",
       " '11146',\n",
       " '13277',\n",
       " '11292',\n",
       " '11109',\n",
       " '13459',\n",
       " '11775',\n",
       " '16218',\n",
       " '14698',\n",
       " '14252',\n",
       " '13256',\n",
       " '13139',\n",
       " '12250',\n",
       " '11259',\n",
       " '11468',\n",
       " '14952',\n",
       " '12402',\n",
       " '14574',\n",
       " '11996',\n",
       " '11977',\n",
       " '11867',\n",
       " '11203',\n",
       " '11995',\n",
       " '15016',\n",
       " '10747',\n",
       " '14905',\n",
       " '12012',\n",
       " '14783',\n",
       " '14730',\n",
       " '10431',\n",
       " '10434',\n",
       " '16869',\n",
       " '10408',\n",
       " '12264',\n",
       " '11618',\n",
       " '15304',\n",
       " '13577',\n",
       " '12954',\n",
       " '11624',\n",
       " '13541',\n",
       " '13422',\n",
       " '14057',\n",
       " '13232',\n",
       " '10800',\n",
       " '14689',\n",
       " '12391',\n",
       " '10868',\n",
       " '14711',\n",
       " '10257',\n",
       " '11067',\n",
       " '10562',\n",
       " '11695',\n",
       " '13796',\n",
       " '14109',\n",
       " '13970',\n",
       " '14193',\n",
       " '11076',\n",
       " '14092',\n",
       " '11122',\n",
       " '11288',\n",
       " '11308',\n",
       " '10754',\n",
       " '12884',\n",
       " '15376',\n",
       " '14588',\n",
       " '11884',\n",
       " '12915',\n",
       " '13851',\n",
       " '14843',\n",
       " '11603',\n",
       " '14457',\n",
       " '12206',\n",
       " '11252',\n",
       " '11905',\n",
       " '15412',\n",
       " '14120',\n",
       " '11980',\n",
       " '14025',\n",
       " '11150',\n",
       " '14709',\n",
       " '15897',\n",
       " '14107',\n",
       " '14006',\n",
       " '14747',\n",
       " '12902',\n",
       " '13061',\n",
       " '12016',\n",
       " '14794',\n",
       " '11921',\n",
       " '10731',\n",
       " '14828',\n",
       " '12889',\n",
       " '12441',\n",
       " '14802',\n",
       " '13230',\n",
       " '10631',\n",
       " '14492',\n",
       " '10141',\n",
       " '13204',\n",
       " '12992',\n",
       " '13184',\n",
       " '10643',\n",
       " '10333',\n",
       " '12255',\n",
       " '14487',\n",
       " '12129',\n",
       " '10551',\n",
       " '13871',\n",
       " '14256',\n",
       " '11066',\n",
       " '13377',\n",
       " '13487',\n",
       " '10627',\n",
       " '12335',\n",
       " '14633',\n",
       " '11274',\n",
       " '14543',\n",
       " '10299',\n",
       " '10158',\n",
       " '12951',\n",
       " '14004',\n",
       " '12544',\n",
       " '10739',\n",
       " '10165',\n",
       " '13964',\n",
       " '14314',\n",
       " '10990',\n",
       " '14812',\n",
       " '12339',\n",
       " '10561',\n",
       " '10146',\n",
       " '12451',\n",
       " '15991',\n",
       " '11423',\n",
       " '15401',\n",
       " '11587',\n",
       " '14520',\n",
       " '11042',\n",
       " '10185',\n",
       " '11278',\n",
       " '14534',\n",
       " '14100',\n",
       " '14321',\n",
       " '11111',\n",
       " '15024',\n",
       " '12917',\n",
       " '12124',\n",
       " '12523',\n",
       " '10821',\n",
       " '10721',\n",
       " '11630',\n",
       " '10170',\n",
       " '12448',\n",
       " '12953',\n",
       " '10918',\n",
       " '15356',\n",
       " '13344',\n",
       " '10676',\n",
       " '10926',\n",
       " '14307',\n",
       " '14635',\n",
       " '12156',\n",
       " '12244',\n",
       " '10666',\n",
       " '11612',\n",
       " '13476',\n",
       " '13029',\n",
       " '11267',\n",
       " '15411',\n",
       " '14986',\n",
       " '11471',\n",
       " '12758',\n",
       " '14576',\n",
       " '10155',\n",
       " '13486',\n",
       " '14716',\n",
       " '13296',\n",
       " '11283',\n",
       " '10732',\n",
       " '12266',\n",
       " '12892',\n",
       " '11003',\n",
       " '12094',\n",
       " '14685',\n",
       " '13158',\n",
       " '13121',\n",
       " '11540',\n",
       " '14877',\n",
       " '12217',\n",
       " '11697',\n",
       " '10372',\n",
       " '13264',\n",
       " '10469',\n",
       " '11336',\n",
       " '14683',\n",
       " '14112',\n",
       " '13502',\n",
       " '14524',\n",
       " '15027',\n",
       " '11973',\n",
       " '12173',\n",
       " '10361',\n",
       " '13388',\n",
       " '13891',\n",
       " '10577',\n",
       " '11433',\n",
       " '13290',\n",
       " '11298',\n",
       " '14771',\n",
       " '11577',\n",
       " '11140',\n",
       " '11057',\n",
       " '15048',\n",
       " '14960',\n",
       " '15295',\n",
       " '11865',\n",
       " '14893',\n",
       " '11049',\n",
       " '13495',\n",
       " '11953',\n",
       " '12223',\n",
       " '14254',\n",
       " '11823',\n",
       " '15380',\n",
       " '11447',\n",
       " '12003',\n",
       " '14489',\n",
       " '14908',\n",
       " '11986',\n",
       " '14082',\n",
       " '12191',\n",
       " '14113',\n",
       " '12891',\n",
       " '15249',\n",
       " '12819',\n",
       " '14570',\n",
       " '12323',\n",
       " '14679',\n",
       " '12343',\n",
       " '13076',\n",
       " '11503',\n",
       " '11617',\n",
       " '10728',\n",
       " '10785',\n",
       " '14869',\n",
       " '14027',\n",
       " '14674',\n",
       " '12197',\n",
       " '14696',\n",
       " '13485',\n",
       " '10781',\n",
       " '10849',\n",
       " '14955',\n",
       " '13433',\n",
       " '15074',\n",
       " '13127',\n",
       " '11013',\n",
       " '14122',\n",
       " '10154',\n",
       " '10980',\n",
       " '14098',\n",
       " '12982',\n",
       " '14512',\n",
       " '12278',\n",
       " '15919',\n",
       " '12478',\n",
       " '13830',\n",
       " '13933',\n",
       " '13930',\n",
       " '11997',\n",
       " '11027',\n",
       " '15582',\n",
       " '11721',\n",
       " '12896',\n",
       " '10279',\n",
       " '11778',\n",
       " '12888',\n",
       " '14262',\n",
       " '11415',\n",
       " '10685',\n",
       " '14842',\n",
       " '14761',\n",
       " '11193',\n",
       " '12265',\n",
       " '14288',\n",
       " '10713',\n",
       " '12397',\n",
       " '15624',\n",
       " '10994',\n",
       " '10409',\n",
       " '12519',\n",
       " '10136',\n",
       " '15607',\n",
       " '14237',\n",
       " '10779',\n",
       " '11898',\n",
       " '11413',\n",
       " '13983',\n",
       " '10558',\n",
       " '10620',\n",
       " '14222',\n",
       " '13198',\n",
       " '10423',\n",
       " '11097',\n",
       " '15454',\n",
       " '15370',\n",
       " '12899',\n",
       " '10135',\n",
       " '12177',\n",
       " '13303',\n",
       " '13795',\n",
       " '10693',\n",
       " '12945',\n",
       " '12511']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'../data/airports.csv', 'r', encoding = 'utf-8') as file:\n",
    "    airports_file = csv.reader(file, delimiter = ',')\n",
    "    airports_ids = []\n",
    "    for row in airports_file:\n",
    "        airports_ids.append(row[0])\n",
    "airports_ids.pop(0)\n",
    "airports_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Downloading `Airport`\n",
    "Downloading data regarding individual airports <br>\n",
    "    Not all airports available in the `airports.csv` file are available in the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_dict = {\"origin_airport_id\":[], \"display_airport_name\":[], \"origin_city_name\":[], \"name\":[]}\n",
    "airport_df = pd.DataFrame(data_dict)\n",
    "\n",
    "for elem in airports_ids:\n",
    "    response = requests.get(f'https://api-datalab.coderslab.com/api/v2/airport/{elem}', headers = headers)\n",
    "    if response.status_code == 200:\n",
    "        air = response.json()\n",
    "        airport_df = airport_df.append({\"origin_airport_id\": f\"{air['ORIGIN_AIRPORT_ID']}\",\n",
    "                                        \"display_airport_name\": air['DISPLAY_AIRPORT_NAME'], \n",
    "                                        \"origin_city_name\": air['ORIGIN_CITY_NAME'], \n",
    "                                        \"name\": air['NAME']}, \n",
    "                             ignore_index = True)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>display_airport_name</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11638</td>\n",
       "      <td>Fresno Air Terminal</td>\n",
       "      <td>Fresno, CA</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13342</td>\n",
       "      <td>General Mitchell Field</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>MILWAUKEE MITCHELL AIRPORT, WI US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13244</td>\n",
       "      <td>Memphis International</td>\n",
       "      <td>Memphis, TN</td>\n",
       "      <td>MEMPHIS INTERNATIONAL AIRPORT, TN US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15096</td>\n",
       "      <td>Syracuse Hancock International</td>\n",
       "      <td>Syracuse, NY</td>\n",
       "      <td>SYRACUSE HANCOCK INTERNATIONAL AIRPORT, NY US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10397</td>\n",
       "      <td>Atlanta Municipal</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>13198</td>\n",
       "      <td>Kansas City International</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>KANSAS CITY INTERNATIONAL AIRPORT, MO US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>10423</td>\n",
       "      <td>Austin - Bergstrom International</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>AUSTIN BERGSTROM INTERNATIONAL AIRPORT, TX US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>15370</td>\n",
       "      <td>Tulsa International</td>\n",
       "      <td>Tulsa, OK</td>\n",
       "      <td>OKLAHOMA CITY WILL ROGERS WORLD AIRPORT, OK US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>13303</td>\n",
       "      <td>Miami International</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>MIAMI INTERNATIONAL AIRPORT, FL US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10693</td>\n",
       "      <td>Myrtle Beach International</td>\n",
       "      <td>Myrtle Beach, SC</td>\n",
       "      <td>NORTH MYRTLE BEACH, SC US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin_airport_id              display_airport_name  origin_city_name  \\\n",
       "0              11638               Fresno Air Terminal        Fresno, CA   \n",
       "1              13342            General Mitchell Field     Milwaukee, WI   \n",
       "2              13244             Memphis International       Memphis, TN   \n",
       "3              15096    Syracuse Hancock International      Syracuse, NY   \n",
       "4              10397                 Atlanta Municipal       Atlanta, GA   \n",
       "..               ...                               ...               ...   \n",
       "92             13198         Kansas City International   Kansas City, MO   \n",
       "93             10423  Austin - Bergstrom International        Austin, TX   \n",
       "94             15370               Tulsa International         Tulsa, OK   \n",
       "95             13303               Miami International         Miami, FL   \n",
       "96             10693        Myrtle Beach International  Myrtle Beach, SC   \n",
       "\n",
       "                                                 name  \n",
       "0                FRESNO YOSEMITE INTERNATIONAL, CA US  \n",
       "1                   MILWAUKEE MITCHELL AIRPORT, WI US  \n",
       "2                MEMPHIS INTERNATIONAL AIRPORT, TN US  \n",
       "3       SYRACUSE HANCOCK INTERNATIONAL AIRPORT, NY US  \n",
       "4   ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...  \n",
       "..                                                ...  \n",
       "92           KANSAS CITY INTERNATIONAL AIRPORT, MO US  \n",
       "93      AUSTIN BERGSTROM INTERNATIONAL AIRPORT, TX US  \n",
       "94     OKLAHOMA CITY WILL ROGERS WORLD AIRPORT, OK US  \n",
       "95                 MIAMI INTERNATIONAL AIRPORT, FL US  \n",
       "96                          NORTH MYRTLE BEACH, SC US  \n",
       "\n",
       "[97 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving dataframe `airport_df` to file `airport_list.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_df.to_csv(r'../data/raw/airport_list.csv', sep = ';', encoding = 'utf-8', index = True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Downloading `Weather`\n",
    " \n",
    " Downloading data on recorded weather at individual airports <br>\n",
    "    The data starting date is `2019-01-01`, and the end date is `2020-03-31`, that is 15 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-01',\n",
       " '2019-02',\n",
       " '2019-03',\n",
       " '2019-04',\n",
       " '2019-05',\n",
       " '2019-06',\n",
       " '2019-07',\n",
       " '2019-08',\n",
       " '2019-09',\n",
       " '2019-10',\n",
       " '2019-11',\n",
       " '2019-12',\n",
       " '2020-01',\n",
       " '2020-02',\n",
       " '2020-03']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_list = []\n",
    "for i in range (1,16,1):\n",
    "    if i <= 9:\n",
    "        dates_list.append(f\"2019-0{i}\")\n",
    "    elif i >= 10 and i <= 12:\n",
    "        dates_list.append(f\"2019-{i}\")\n",
    "    elif i > 12:\n",
    "        dates_list.append(f\"2020-0{i - 12}\")\n",
    "dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for elem in dates_list:\n",
    "    data_to_send = {\n",
    "            'date': elem}\n",
    "    response = requests.get(f'https://api-datalab.coderslab.com/api/v2/airportWeather', \n",
    "                            params = data_to_send, \n",
    "                            headers = headers)\n",
    "    data_weather = response.json()\n",
    "    for elem in data_weather:\n",
    "        data.append(elem)\n",
    "weather_df = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving dataframe `weather_df` to file `airport_weather.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.to_csv(r'../data/raw/airport_weather.csv', sep = ';', encoding = 'utf-8', index = True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Downloading `Aircraft`\n",
    " Downloading data about aircraft production details <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f'https://api-datalab.coderslab.com/api/v2/aircraft', \n",
    "                        headers = headers)\n",
    "aircraft_data = response.json()\n",
    "\n",
    "data2 = []\n",
    "for elem in aircraft_data:\n",
    "    data2.append(elem)\n",
    "aircraft_df = pd.DataFrame.from_records(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving dataframe `aircraft_df` to file `aircraft.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircraft_df.to_csv(r'../data/raw/aircraft.csv', sep = ';', encoding = 'utf-8', index = True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Downloading `Flight`\n",
    " Downloading air traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = []\n",
    "for row in airports_ids:\n",
    "    for elem in dates_list:\n",
    "        data_to_send = {\n",
    "                'airportId': row,\n",
    "                'date': elem}\n",
    "        response = requests.get(f'https://api-datalab.coderslab.com/api/v2/flight', \n",
    "                                params = data_to_send, \n",
    "                                headers = headers)\n",
    "        if response.status_code == 200:\n",
    "            flight_data = response.json()\n",
    "            for f in flight_data:\n",
    "                data3.append(f)\n",
    "        else:\n",
    "            continue\n",
    "flight_df = pd.DataFrame.from_records(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving dataframe `flight_df` to file `flight.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df.to_csv(r'../data/raw/flight.csv', sep = ';', encoding = 'utf-8', index = True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sum up\n",
    "In this notebook, I have completed the basic step in data analysis - I have acquired the data. They are ready for further work, i.e. now we can load them into the database and then see what information they carry. Subsequent notebooks will serve precisely these purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "38d75d0df746d7f75dd34c5d1915af59cb55786647bd68b8d9064425d7680b12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
